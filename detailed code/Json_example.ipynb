{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json 파일 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading https://files.pythonhosted.org/packages/68/ad/6c2406ae175f59ec616714e408979b674fe27b9587f79d59a528ddfbcd5b/seaborn-0.11.1-py3-none-any.whl (285kB)\n",
      "\u001b[K    100% |████████████████████████████████| 286kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.23 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/e2/00cacecafbab071c787019f00ad84ca3185952f6bb9bca9550ed83870d4d/pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting matplotlib>=2.2 (from seaborn)\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/43/2bd63467490036697e7be71444fafc7b236923d614d4521979a200c6b559/matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 11.6MB 111kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting scipy>=1.0 (from seaborn)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.9MB 54kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.15 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/a6/fc/36e52d0ae2aa502b211f1bcd2fdeec72d343d58224eabcdddc1bcb052db1/numpy-1.19.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2017.2 (from pandas>=0.23->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.7.3 (from pandas>=0.23->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pillow>=6.2.0 (from matplotlib>=2.2->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.2->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=2.2->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 (from matplotlib>=2.2->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7.3->pandas>=0.23->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Installing collected packages: pytz, numpy, six, python-dateutil, pandas, pillow, cycler, kiwisolver, pyparsing, matplotlib, scipy, seaborn\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.3 numpy-1.19.4 pandas-1.1.5 pillow-8.0.1 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 scipy-1.5.4 seaborn-0.11.1 six-1.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value1': 5, 'value2': 10, 'seq': [1, 2, 3, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "a = {'value1':5, 'value2':10, 'seq':[1,2,3,4,5]}  # 리스트 형태의 딕셔너리도 저장가능\n",
    "\n",
    "filename = 'test.json'\n",
    "with open(filename, 'w') as f:    # 파일 쓰기, with 문을 나가게 되면 자동으로 파일이 닫혀서 안전하게 사용함\n",
    "    json.dump(a, f)                # 딕셔너리 형태로 파일 저장\n",
    "    \n",
    "with open(filename, 'r') as f:    # 파일 읽기\n",
    "    result = json.load(f)\n",
    "    print(result)\n",
    "    \n",
    "# 파일 이름은 시간_랜덤 숫자로 지정해서 알아보기 쉽게 만들기\n",
    "# 같은 실험 세팅으로 다시 돌리면 시간이 달라서 다른 json 파일이 생김\n",
    "# 변수 값들을 파일 제목에 같이 넣어보자 구분하기 쉽게\n",
    "# 근데 하이퍼 파라미터가 많음, 모두 다 넣을 수가 없음\n",
    "# 그러면 실험 이름 + 실험 세팅 값의 해쉬.json 으로 파일 이름을 정하자.\n",
    "\n",
    "# 해쉬 : 문자, 숫자의 조합의 규칙으로 표현하는 것, input 값이 달라지면 조합이 완전히 달라짐. 랜덤하게 보이지만 규칙이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 해쉬 값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c40aaa\n",
      "10e2f9\n",
      "c40aaa\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "setting1 = {'value1': 5, 'value2': 10, 'seq': [1, 2, 3, 4, 5]}         # 딕셔너리라서 해쉬로 바로 바꿀수가 없음\n",
    "setting2 = {'value1': 6, 'value2': 10, 'seq': [1, 2, 3, 4, 5]}        \n",
    "setting3 = {'value1': 5, 'value2': 10, 'seq': [1, 2, 3, 4, 5]}        \n",
    "\n",
    "hash_key1 = hashlib.sha1(str(setting1).encode()).hexdigest()[:6]       # 딕셔너리 -> 문자열로 바꾼 후 해쉬로 변경\n",
    "hash_key2 = hashlib.sha1(str(setting2).encode()).hexdigest()[:6]       \n",
    "hash_key3 = hashlib.sha1(str(setting3).encode()).hexdigest()[:6]       \n",
    "\n",
    "print(hash_key1)  # 내용이 같으면 \n",
    "print(hash_key2) \n",
    "print(hash_key3)  # 같은 해쉬값 만드는 것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 이름 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1-4766aa.json\n"
     ]
    }
   ],
   "source": [
    "setting = {'value1': 5, 'value2': 10, 'seq': [1, 2, 3, 4, 5], 'exp_name': 'exp1'}\n",
    "exp_name = setting['exp_name']\n",
    "hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]  \n",
    "filename = '{}-{}.json'.format(exp_name, hash_key)\n",
    "    \n",
    "print(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리눅스 파일 확인 명령어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 02-supervised-learning_aiml.ipynb    myenv\n",
      " Anaconda3-2019.07-Linux-x86_64.sh    mytree.dot\n",
      " Json_example.ipynb\t\t      preamble.py\n",
      " Manifold_S_Dataset_AIML.ipynb\t      results\n",
      " Manifold_Sphere_Dataset_AIML.ipynb   scikit_learn_data\n",
      " StandAlone.ipynb\t\t      test.json\n",
      " __pycache__\t\t\t      tmp\n",
      " anaconda3\t\t\t      tmp.png\n",
      " cache\t\t\t\t      tree.dot\n",
      " data\t\t\t\t      unsupervised-learning-AIML.ipynb\n",
      " jupyter-notebook-tutorial-yu.ipynb   서버사용법.txt\n",
      " model_evaluation_AIML.ipynb\t     '인공지능및기계학습(21611616박민재).ipynb'\n",
      "{\"value1\": 5, \"value2\": 10, \"seq\": [1, 2, 3, 4, 5]}"
     ]
    }
   ],
   "source": [
    "!ls              # 폴더 내 파일 확인하는 명령어\n",
    "!cat test.json   # 파일 내용 확인하는 명령어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `results' 디렉토리를 만들 수 없습니다: 파일이 있습니다\n",
      " 02-supervised-learning_aiml.ipynb    myenv\n",
      " Anaconda3-2019.07-Linux-x86_64.sh    mytree.dot\n",
      " Json_example.ipynb\t\t      preamble.py\n",
      " Manifold_S_Dataset_AIML.ipynb\t      results\n",
      " Manifold_Sphere_Dataset_AIML.ipynb   scikit_learn_data\n",
      " StandAlone.ipynb\t\t      test.json\n",
      " __pycache__\t\t\t      tmp\n",
      " anaconda3\t\t\t      tmp.png\n",
      " cache\t\t\t\t      tree.dot\n",
      " data\t\t\t\t      unsupervised-learning-AIML.ipynb\n",
      " jupyter-notebook-tutorial-yu.ipynb   서버사용법.txt\n",
      " model_evaluation_AIML.ipynb\t     '인공지능및기계학습(21611616박민재).ipynb'\n"
     ]
    }
   ],
   "source": [
    "!mkdir results    # result 파일 만들기\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 및 실험 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy # Add Deepcopy for args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hid_dim, n_layer, act, dropout, use_bn, use_xavier):\n",
    "        super(MLP, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layer = n_layer\n",
    "        self.act = act\n",
    "        self.dropout = dropout\n",
    "        self.use_bn = use_bn\n",
    "        self.use_xavier = use_xavier\n",
    "        \n",
    "        # ====== Create Linear Layers ====== #\n",
    "        self.fc1 = nn.Linear(self.in_dim, self.hid_dim)\n",
    "        \n",
    "        self.linears = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        for i in range(self.n_layer-1):\n",
    "            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n",
    "            if self.use_bn:\n",
    "                self.bns.append(nn.BatchNorm1d(self.hid_dim))\n",
    "                \n",
    "        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n",
    "        \n",
    "        # ====== Create Activation Function ====== #\n",
    "        if self.act == 'relu':\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.act == 'tanh':\n",
    "            self.act == nn.Tanh()\n",
    "        elif self.act == 'sigmoid':\n",
    "            self.act = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError('no valid activation function selected!')\n",
    "        \n",
    "        # ====== Create Regularization Layer ======= #\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        if self.use_xavier:\n",
    "            self.xavier_init()\n",
    "          \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.fc1(x))\n",
    "        for i in range(len(self.linears)):\n",
    "            x = self.act(self.linears[i](x))\n",
    "            x = self.bns[i](x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def xavier_init(self):\n",
    "        for linear in self.linears:\n",
    "            nn.init.xavier_normal_(linear.weight)\n",
    "            linear.bias.data.fill_(0.01)\n",
    "            \n",
    "net = MLP(3072, 10, 100, 4, 'relu', 0.1, True, True) # Testing Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, partition, optimizer, criterion, args):\n",
    "    trainloader = torch.utils.data.DataLoader(partition['train'], \n",
    "                                              batch_size=args.train_batch_size, \n",
    "                                              shuffle=True, num_workers=2)\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, 3072)\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return net, train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, partition, criterion, args):\n",
    "    valloader = torch.utils.data.DataLoader(partition['val'], \n",
    "                                            batch_size=args.test_batch_size, \n",
    "                                            shuffle=False, num_workers=2)\n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images = images.view(-1, 3072)\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, partition, args):\n",
    "    testloader = torch.utils.data.DataLoader(partition['test'], \n",
    "                                             batch_size=args.test_batch_size, \n",
    "                                             shuffle=False, num_workers=2)\n",
    "    net.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.view(-1, 3072)\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "  \n",
    "    net = MLP(args.in_dim, args.out_dim, args.hid_dim, args.n_layer, args.act, args.dropout, args.use_bn, args.use_xavier)\n",
    "    net.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "    \n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    # ===================================== #\n",
    "        \n",
    "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
    "        ts = time.time()\n",
    "        net, train_loss, train_acc = train(net, partition, optimizer, criterion, args)\n",
    "        val_loss, val_acc = validate(net, partition, criterion, args)\n",
    "        te = time.time()\n",
    "        \n",
    "        # ====== Add Epoch Data ====== #\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        # ============================ #\n",
    "        \n",
    "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
    "        \n",
    "    test_acc = test(net, partition, args)    \n",
    "    \n",
    "    # ======= Add Result to Dictionary ======= #\n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['train_accs'] = train_accs\n",
    "    result['val_accs'] = val_accs\n",
    "    result['train_acc'] = train_acc\n",
    "    result['val_acc'] = val_acc\n",
    "    result['test_acc'] = test_acc\n",
    "    return vars(args), result\n",
    "    # ===================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "\n",
    "def save_exp_result(setting, result):\n",
    "    exp_name = setting['exp_name']\n",
    "    del setting['epoch']\n",
    "    del setting['test_batch_size']\n",
    "\n",
    "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
    "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n",
    "    result.update(setting)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "\n",
    "    \n",
    "def load_exp_result(exp_name):\n",
    "    dir_path = './results'\n",
    "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
    "    list_result = []\n",
    "    for filename in filenames:\n",
    "        if exp_name in filename:\n",
    "            with open(join(dir_path, filename), 'r') as infile:\n",
    "                results = json.load(infile)\n",
    "                list_result.append(results)\n",
    "    df = pd.DataFrame(list_result) # .drop(columns=[])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(act='relu', dropout=0.2, epoch=10, exp_name='exp1_n_layer_hid_dim', hid_dim=500, in_dim=3072, l2=1e-05, lr=0.0015, n_layer=1, optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True, use_xavier=True)\n",
      "Epoch 0, Acc(train/val): 23.72/25.40, Loss(train/val) 24.76/35.40. Took 5.45 sec\n",
      "Epoch 1, Acc(train/val): 24.86/24.21, Loss(train/val) 24.53/24.27. Took 5.58 sec\n",
      "Epoch 2, Acc(train/val): 26.61/25.34, Loss(train/val) 17.84/20.52. Took 4.98 sec\n",
      "Epoch 3, Acc(train/val): 26.58/27.30, Loss(train/val) 21.12/25.80. Took 5.22 sec\n",
      "Epoch 4, Acc(train/val): 28.17/26.19, Loss(train/val) 17.52/26.68. Took 5.22 sec\n",
      "Epoch 5, Acc(train/val): 27.25/25.43, Loss(train/val) 18.27/23.98. Took 5.56 sec\n",
      "Epoch 6, Acc(train/val): 27.91/25.89, Loss(train/val) 17.56/22.07. Took 5.49 sec\n",
      "Epoch 7, Acc(train/val): 28.19/23.50, Loss(train/val) 18.44/22.31. Took 5.49 sec\n",
      "Epoch 8, Acc(train/val): 28.77/27.43, Loss(train/val) 16.09/24.27. Took 5.58 sec\n",
      "Epoch 9, Acc(train/val): 29.07/25.74, Loss(train/val) 16.77/22.03. Took 5.27 sec\n",
      "Namespace(act='relu', dropout=0.2, epoch=10, exp_name='exp1_n_layer_hid_dim', hid_dim=300, in_dim=3072, l2=1e-05, lr=0.0015, n_layer=1, optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True, use_xavier=True)\n",
      "Epoch 0, Acc(train/val): 24.06/23.89, Loss(train/val) 15.74/18.69. Took 5.51 sec\n",
      "Epoch 1, Acc(train/val): 25.27/24.77, Loss(train/val) 14.06/14.59. Took 5.52 sec\n",
      "Epoch 2, Acc(train/val): 25.73/23.67, Loss(train/val) 11.67/14.06. Took 5.22 sec\n",
      "Epoch 3, Acc(train/val): 26.40/25.19, Loss(train/val) 10.71/13.31. Took 5.50 sec\n",
      "Epoch 4, Acc(train/val): 26.38/25.50, Loss(train/val) 10.70/15.96. Took 5.47 sec\n",
      "Epoch 5, Acc(train/val): 26.00/23.36, Loss(train/val) 11.02/13.17. Took 5.02 sec\n",
      "Epoch 6, Acc(train/val): 26.53/24.90, Loss(train/val) 11.67/14.32. Took 5.23 sec\n",
      "Epoch 7, Acc(train/val): 27.75/28.24, Loss(train/val) 10.86/13.88. Took 5.37 sec\n",
      "Epoch 8, Acc(train/val): 27.20/25.87, Loss(train/val) 11.07/14.77. Took 5.56 sec\n",
      "Epoch 9, Acc(train/val): 27.69/26.13, Loss(train/val) 9.81/12.93. Took 5.68 sec\n",
      "Namespace(act='relu', dropout=0.2, epoch=10, exp_name='exp1_n_layer_hid_dim', hid_dim=500, in_dim=3072, l2=1e-05, lr=0.0015, n_layer=2, optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True, use_xavier=True)\n",
      "Epoch 0, Acc(train/val): 28.79/31.66, Loss(train/val) 2.01/3.35. Took 5.60 sec\n",
      "Epoch 1, Acc(train/val): 33.81/33.90, Loss(train/val) 1.84/2.27. Took 5.09 sec\n",
      "Epoch 2, Acc(train/val): 36.45/37.87, Loss(train/val) 1.76/2.59. Took 5.53 sec\n",
      "Epoch 3, Acc(train/val): 38.40/40.88, Loss(train/val) 1.72/5.20. Took 5.08 sec\n",
      "Epoch 4, Acc(train/val): 41.37/42.53, Loss(train/val) 1.64/1.65. Took 5.66 sec\n",
      "Epoch 5, Acc(train/val): 43.31/43.19, Loss(train/val) 1.58/1.62. Took 5.39 sec\n",
      "Epoch 6, Acc(train/val): 45.12/44.37, Loss(train/val) 1.54/1.79. Took 5.41 sec\n",
      "Epoch 7, Acc(train/val): 46.98/46.37, Loss(train/val) 1.49/1.53. Took 5.37 sec\n",
      "Epoch 8, Acc(train/val): 48.92/47.34, Loss(train/val) 1.44/1.62. Took 5.33 sec\n",
      "Epoch 9, Acc(train/val): 51.05/48.49, Loss(train/val) 1.38/1.55. Took 5.47 sec\n",
      "Namespace(act='relu', dropout=0.2, epoch=10, exp_name='exp1_n_layer_hid_dim', hid_dim=300, in_dim=3072, l2=1e-05, lr=0.0015, n_layer=2, optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True, use_xavier=True)\n",
      "Epoch 0, Acc(train/val): 29.60/34.40, Loss(train/val) 1.95/1.97. Took 5.53 sec\n",
      "Epoch 1, Acc(train/val): 33.90/35.81, Loss(train/val) 1.83/1.75. Took 5.50 sec\n",
      "Epoch 2, Acc(train/val): 37.22/37.99, Loss(train/val) 1.74/1.72. Took 5.15 sec\n",
      "Epoch 3, Acc(train/val): 39.15/39.66, Loss(train/val) 1.69/1.66. Took 5.55 sec\n",
      "Epoch 4, Acc(train/val): 41.91/42.39, Loss(train/val) 1.63/1.60. Took 5.48 sec\n",
      "Epoch 5, Acc(train/val): 44.46/44.47, Loss(train/val) 1.56/1.55. Took 5.46 sec\n",
      "Epoch 6, Acc(train/val): 46.70/46.79, Loss(train/val) 1.50/1.50. Took 5.52 sec\n",
      "Epoch 7, Acc(train/val): 48.95/47.54, Loss(train/val) 1.44/1.49. Took 5.54 sec\n",
      "Epoch 8, Acc(train/val): 50.29/47.88, Loss(train/val) 1.40/1.47. Took 5.62 sec\n",
      "Epoch 9, Acc(train/val): 52.09/48.87, Loss(train/val) 1.35/1.46. Took 5.13 sec\n",
      "Namespace(act='relu', dropout=0.2, epoch=10, exp_name='exp1_n_layer_hid_dim', hid_dim=500, in_dim=3072, l2=1e-05, lr=0.0015, n_layer=3, optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True, use_xavier=True)\n",
      "Epoch 0, Acc(train/val): 27.48/32.07, Loss(train/val) 2.05/1.90. Took 5.47 sec\n",
      "Epoch 1, Acc(train/val): 33.31/34.95, Loss(train/val) 1.84/2.79. Took 5.31 sec\n",
      "Epoch 2, Acc(train/val): 36.44/38.25, Loss(train/val) 1.76/6.55. Took 5.45 sec\n",
      "Epoch 3, Acc(train/val): 38.35/40.31, Loss(train/val) 1.70/20.91. Took 5.23 sec\n",
      "Epoch 4, Acc(train/val): 41.05/42.78, Loss(train/val) 1.64/2.24. Took 5.48 sec\n",
      "Epoch 5, Acc(train/val): 43.98/44.18, Loss(train/val) 1.57/1.54. Took 5.21 sec\n",
      "Epoch 6, Acc(train/val): 46.28/46.10, Loss(train/val) 1.51/5.92. Took 5.22 sec\n",
      "Epoch 7, Acc(train/val): 48.39/47.51, Loss(train/val) 1.45/1.49. Took 5.06 sec\n",
      "Epoch 8, Acc(train/val): 50.48/48.23, Loss(train/val) 1.40/1.54. Took 5.38 sec\n",
      "Epoch 9, Acc(train/val): 52.34/48.49, Loss(train/val) 1.34/1.46. Took 4.94 sec\n",
      "Namespace(act='relu', dropout=0.2, epoch=10, exp_name='exp1_n_layer_hid_dim', hid_dim=300, in_dim=3072, l2=1e-05, lr=0.0015, n_layer=3, optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True, use_xavier=True)\n",
      "Epoch 0, Acc(train/val): 29.75/35.45, Loss(train/val) 1.94/1.89. Took 5.19 sec\n",
      "Epoch 1, Acc(train/val): 35.03/38.03, Loss(train/val) 1.79/1.82. Took 5.05 sec\n",
      "Epoch 2, Acc(train/val): 37.97/39.34, Loss(train/val) 1.72/1.68. Took 5.22 sec\n",
      "Epoch 3, Acc(train/val): 39.84/41.32, Loss(train/val) 1.67/1.65. Took 5.32 sec\n",
      "Epoch 4, Acc(train/val): 42.31/42.98, Loss(train/val) 1.61/1.57. Took 5.44 sec\n",
      "Epoch 5, Acc(train/val): 44.92/43.85, Loss(train/val) 1.54/1.61. Took 5.23 sec\n",
      "Epoch 6, Acc(train/val): 46.75/45.33, Loss(train/val) 1.49/1.53. Took 5.44 sec\n",
      "Epoch 7, Acc(train/val): 49.47/46.43, Loss(train/val) 1.42/1.50. Took 5.45 sec\n",
      "Epoch 8, Acc(train/val): 51.17/47.53, Loss(train/val) 1.37/1.48. Took 5.53 sec\n",
      "Epoch 9, Acc(train/val): 52.89/49.61, Loss(train/val) 1.33/1.43. Took 5.56 sec\n"
     ]
    }
   ],
   "source": [
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"exp1_n_layer_hid_dim\"\n",
    "\n",
    "# ====== Model Capacity ====== #\n",
    "args.in_dim = 3072\n",
    "args.out_dim = 10\n",
    "args.hid_dim = 100\n",
    "args.act = 'relu'\n",
    "\n",
    "# ====== Regularization ======= #\n",
    "args.dropout = 0.2\n",
    "args.use_bn = True\n",
    "args.l2 = 0.00001\n",
    "args.use_xavier = True\n",
    "\n",
    "# ====== Optimizer & Training ====== #\n",
    "args.optim = 'RMSprop' #'RMSprop' #SGD, RMSprop, ADAM...\n",
    "args.lr = 0.0015\n",
    "args.epoch = 10\n",
    "\n",
    "args.train_batch_size = 256\n",
    "args.test_batch_size = 1024\n",
    "\n",
    "# ====== Experiment Variable ====== #\n",
    "name_var1 = 'n_layer'\n",
    "name_var2 = 'hid_dim'\n",
    "list_var1 = [1, 2, 3]\n",
    "list_var2 = [500, 300]\n",
    "\n",
    "\n",
    "for var1 in list_var1:\n",
    "    for var2 in list_var2:\n",
    "        setattr(args, name_var1, var1)      # args.name_var1 = var1\n",
    "        setattr(args, name_var2, var2)\n",
    "        print(args)\n",
    "                \n",
    "        setting, result = experiment(partition, deepcopy(args))\n",
    "        save_exp_result(setting, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1_n_layer_hid_dim-41b634.json  exp1_n_layer_hid_dim-bfc899.json\n",
      "exp1_n_layer_hid_dim-61a2d0.json  exp1_n_layer_hid_dim-cab8c1.json\n",
      "exp1_n_layer_hid_dim-7b70fe.json  exp1_n_layer_hid_dim-dece45.json\n",
      "{\"train_losses\": [2.0471453127587678, 1.837945068717762, 1.7578448520344534, 1.6970238996918794, 1.6394727533789957, 1.5681930863933198, 1.5053132385205312, 1.4507168835135782, 1.398161703613913, 1.3441456943560557], \"val_losses\": [1.901325237751007, 2.7931323051452637, 6.55473484992981, 20.907688975334167, 2.240697133541107, 1.5426671862602235, 5.915008187294006, 1.4897508382797242, 1.5351552367210388, 1.4601335883140565], \"train_accs\": [27.4825, 33.315, 36.4375, 38.355, 41.05, 43.98, 46.2775, 48.3875, 50.4825, 52.3425], \"val_accs\": [32.07, 34.95, 38.25, 40.31, 42.78, 44.18, 46.1, 47.51, 48.23, 48.49], \"train_acc\": 52.3425, \"val_acc\": 48.49, \"test_acc\": 48.94, \"exp_name\": \"exp1_n_layer_hid_dim\", \"in_dim\": 3072, \"out_dim\": 10, \"hid_dim\": 500, \"act\": \"relu\", \"dropout\": 0.2, \"use_bn\": true, \"l2\": 1e-05, \"use_xavier\": true, \"optim\": \"RMSprop\", \"lr\": 0.0015, \"train_batch_size\": 256, \"n_layer\": 3}"
     ]
    }
   ],
   "source": [
    "!ls results\n",
    "!cat results/exp1_n_layer_hid_dim-bfc899.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_losses</th>\n",
       "      <th>val_losses</th>\n",
       "      <th>train_accs</th>\n",
       "      <th>val_accs</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>in_dim</th>\n",
       "      <th>out_dim</th>\n",
       "      <th>hid_dim</th>\n",
       "      <th>act</th>\n",
       "      <th>dropout</th>\n",
       "      <th>use_bn</th>\n",
       "      <th>l2</th>\n",
       "      <th>use_xavier</th>\n",
       "      <th>optim</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>n_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.9432627365088007, 1.7929904681102486, 1.718...</td>\n",
       "      <td>[1.890033209323883, 1.8202382564544677, 1.6774...</td>\n",
       "      <td>[29.755, 35.0275, 37.9725, 39.835, 42.3125, 44...</td>\n",
       "      <td>[35.45, 38.03, 39.34, 41.32, 42.98, 43.85, 45....</td>\n",
       "      <td>52.8925</td>\n",
       "      <td>49.61</td>\n",
       "      <td>49.40</td>\n",
       "      <td>exp1_n_layer_hid_dim</td>\n",
       "      <td>3072</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.0073414107037197, 1.8399447711410037, 1.757...</td>\n",
       "      <td>[3.3494280576705933, 2.26635400056839, 2.59456...</td>\n",
       "      <td>[28.7925, 33.815, 36.455, 38.3975, 41.3725, 43...</td>\n",
       "      <td>[31.66, 33.9, 37.87, 40.88, 42.53, 43.19, 44.3...</td>\n",
       "      <td>51.0550</td>\n",
       "      <td>48.49</td>\n",
       "      <td>48.50</td>\n",
       "      <td>exp1_n_layer_hid_dim</td>\n",
       "      <td>3072</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2.0471453127587678, 1.837945068717762, 1.7578...</td>\n",
       "      <td>[1.901325237751007, 2.7931323051452637, 6.5547...</td>\n",
       "      <td>[27.4825, 33.315, 36.4375, 38.355, 41.05, 43.9...</td>\n",
       "      <td>[32.07, 34.95, 38.25, 40.31, 42.78, 44.18, 46....</td>\n",
       "      <td>52.3425</td>\n",
       "      <td>48.49</td>\n",
       "      <td>48.94</td>\n",
       "      <td>exp1_n_layer_hid_dim</td>\n",
       "      <td>3072</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15.741769944026972, 14.063796207403682, 11.67...</td>\n",
       "      <td>[18.691005516052247, 14.590527725219726, 14.06...</td>\n",
       "      <td>[24.06, 25.2675, 25.7275, 26.4025, 26.3775, 26...</td>\n",
       "      <td>[23.89, 24.77, 23.67, 25.19, 25.5, 23.36, 24.9...</td>\n",
       "      <td>27.6925</td>\n",
       "      <td>26.13</td>\n",
       "      <td>26.45</td>\n",
       "      <td>exp1_n_layer_hid_dim</td>\n",
       "      <td>3072</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[24.756574389281546, 24.527069893612225, 17.84...</td>\n",
       "      <td>[35.400817489624025, 24.271497535705567, 20.51...</td>\n",
       "      <td>[23.72, 24.8625, 26.6075, 26.5825, 28.17, 27.2...</td>\n",
       "      <td>[25.4, 24.21, 25.34, 27.3, 26.19, 25.43, 25.89...</td>\n",
       "      <td>29.0725</td>\n",
       "      <td>25.74</td>\n",
       "      <td>25.74</td>\n",
       "      <td>exp1_n_layer_hid_dim</td>\n",
       "      <td>3072</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1.9537799662085855, 1.8267348237857697, 1.741...</td>\n",
       "      <td>[1.9749881386756898, 1.7535515785217286, 1.719...</td>\n",
       "      <td>[29.6025, 33.9, 37.215, 39.1475, 41.915, 44.46...</td>\n",
       "      <td>[34.4, 35.81, 37.99, 39.66, 42.39, 44.47, 46.7...</td>\n",
       "      <td>52.0875</td>\n",
       "      <td>48.87</td>\n",
       "      <td>48.80</td>\n",
       "      <td>exp1_n_layer_hid_dim</td>\n",
       "      <td>3072</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        train_losses  \\\n",
       "0  [1.9432627365088007, 1.7929904681102486, 1.718...   \n",
       "1  [2.0073414107037197, 1.8399447711410037, 1.757...   \n",
       "2  [2.0471453127587678, 1.837945068717762, 1.7578...   \n",
       "3  [15.741769944026972, 14.063796207403682, 11.67...   \n",
       "4  [24.756574389281546, 24.527069893612225, 17.84...   \n",
       "5  [1.9537799662085855, 1.8267348237857697, 1.741...   \n",
       "\n",
       "                                          val_losses  \\\n",
       "0  [1.890033209323883, 1.8202382564544677, 1.6774...   \n",
       "1  [3.3494280576705933, 2.26635400056839, 2.59456...   \n",
       "2  [1.901325237751007, 2.7931323051452637, 6.5547...   \n",
       "3  [18.691005516052247, 14.590527725219726, 14.06...   \n",
       "4  [35.400817489624025, 24.271497535705567, 20.51...   \n",
       "5  [1.9749881386756898, 1.7535515785217286, 1.719...   \n",
       "\n",
       "                                          train_accs  \\\n",
       "0  [29.755, 35.0275, 37.9725, 39.835, 42.3125, 44...   \n",
       "1  [28.7925, 33.815, 36.455, 38.3975, 41.3725, 43...   \n",
       "2  [27.4825, 33.315, 36.4375, 38.355, 41.05, 43.9...   \n",
       "3  [24.06, 25.2675, 25.7275, 26.4025, 26.3775, 26...   \n",
       "4  [23.72, 24.8625, 26.6075, 26.5825, 28.17, 27.2...   \n",
       "5  [29.6025, 33.9, 37.215, 39.1475, 41.915, 44.46...   \n",
       "\n",
       "                                            val_accs  train_acc  val_acc  \\\n",
       "0  [35.45, 38.03, 39.34, 41.32, 42.98, 43.85, 45....    52.8925    49.61   \n",
       "1  [31.66, 33.9, 37.87, 40.88, 42.53, 43.19, 44.3...    51.0550    48.49   \n",
       "2  [32.07, 34.95, 38.25, 40.31, 42.78, 44.18, 46....    52.3425    48.49   \n",
       "3  [23.89, 24.77, 23.67, 25.19, 25.5, 23.36, 24.9...    27.6925    26.13   \n",
       "4  [25.4, 24.21, 25.34, 27.3, 26.19, 25.43, 25.89...    29.0725    25.74   \n",
       "5  [34.4, 35.81, 37.99, 39.66, 42.39, 44.47, 46.7...    52.0875    48.87   \n",
       "\n",
       "   test_acc              exp_name  in_dim  out_dim  hid_dim   act  dropout  \\\n",
       "0     49.40  exp1_n_layer_hid_dim    3072       10      300  relu      0.2   \n",
       "1     48.50  exp1_n_layer_hid_dim    3072       10      500  relu      0.2   \n",
       "2     48.94  exp1_n_layer_hid_dim    3072       10      500  relu      0.2   \n",
       "3     26.45  exp1_n_layer_hid_dim    3072       10      300  relu      0.2   \n",
       "4     25.74  exp1_n_layer_hid_dim    3072       10      500  relu      0.2   \n",
       "5     48.80  exp1_n_layer_hid_dim    3072       10      300  relu      0.2   \n",
       "\n",
       "   use_bn       l2  use_xavier    optim      lr  train_batch_size  n_layer  \n",
       "0    True  0.00001        True  RMSprop  0.0015               256        3  \n",
       "1    True  0.00001        True  RMSprop  0.0015               256        2  \n",
       "2    True  0.00001        True  RMSprop  0.0015               256        3  \n",
       "3    True  0.00001        True  RMSprop  0.0015               256        1  \n",
       "4    True  0.00001        True  RMSprop  0.0015               256        1  \n",
       "5    True  0.00001        True  RMSprop  0.0015               256        2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_exp_result('exp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>score</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>m</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>f</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>m</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender  score  t\n",
       "0    5      f     10  1\n",
       "1    6      m      9  1\n",
       "2   10      f     15  1\n",
       "3    8      m     20  2\n",
       "4    3      f     33  2\n",
       "5    3      m     10  2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(load_exp_result('exp1')))\n",
    "\n",
    "a = [{'age':5, 'gender':'f', 'score':10, 't':1}, {'age':6, 'gender':'m', 'score':9, 't':1}, {'age':10, 'gender':'f', 'score':15, 't':1}, {'age':8, 'gender':'m', 'score':20, 't':2}, {'age':3, 'gender':'f', 'score':33, 't':2}, {'age':3, 'gender':'m', 'score':10, 't':2}]\n",
    "df = pd.DataFrame(a)\n",
    "df                    # 밑의 표에서 x : age, y : gender 에 따른 값 : score을 나타내고 싶음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='score'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns # matplotlib보다 더 많은 기능이 있는 클래스\n",
    "sns.barplot(x='age', y='score', hue='gender', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='n_layer', ylabel='test_acc'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = load_exp_result('exp1')\n",
    "\n",
    "sns.barplot(x='n_layer', y='test_acc', hue='hid_dim', data=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='n_layer', ylabel='test_acc'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "fig.set_size_inches(15, 6)\n",
    "#sns.set_style(\"darkgrid\n",
    "\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "sns.barplot(x='n_layer', y='train_acc', hue='hid_dim', data=result, ax=ax[0])\n",
    "sns.barplot(x='n_layer', y='val_acc', hue='hid_dim', data=result, ax=ax[1])\n",
    "sns.barplot(x='n_layer', y='test_acc', hue='hid_dim', data=result, ax=ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
