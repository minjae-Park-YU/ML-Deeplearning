{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet_example.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNi/qTg7ahKWPuATCOQJlal"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"P4jyY-KxmQz3"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.backends.cudnn as cudnn\r\n","import torch.optim as optim\r\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmhoYBbJm6nX"},"source":["# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의\r\n","class BasicBlock(nn.Module):\r\n","    def __init__(self, in_planes, planes, stride=1):\r\n","        super(BasicBlock, self).__init__()\r\n","\r\n","        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\r\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\r\n","\r\n","        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\r\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\r\n","\r\n","        self.shortcut = nn.Sequential() # identity인 경우\r\n","        if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우\r\n","            self.shortcut = nn.Sequential(\r\n","                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\r\n","                nn.BatchNorm2d(planes)\r\n","            )\r\n","\r\n","    def forward(self, x):\r\n","        out = F.relu(self.bn1(self.conv1(x)))\r\n","        out = self.bn2(self.conv2(out))\r\n","        out += self.shortcut(x) # (핵심) skip connection\r\n","        out = F.relu(out)\r\n","        return out\r\n","\r\n","\r\n","# ResNet 클래스 정의\r\n","class ResNet(nn.Module):\r\n","    def __init__(self, block, num_blocks, num_classes=10):\r\n","        super(ResNet, self).__init__()\r\n","        self.in_planes = 64\r\n","\r\n","        # 64개의 3x3 필터(filter)를 사용\r\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(64)\r\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\r\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\r\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\r\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\r\n","        self.linear = nn.Linear(512, num_classes)\r\n","\r\n","    def _make_layer(self, block, planes, num_blocks, stride):\r\n","        strides = [stride] + [1] * (num_blocks - 1)\r\n","        layers = []\r\n","        for stride in strides:\r\n","            layers.append(block(self.in_planes, planes, stride))\r\n","            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\r\n","        return nn.Sequential(*layers)\r\n","\r\n","    def forward(self, x):\r\n","        out = F.relu(self.bn1(self.conv1(x)))\r\n","        out = self.layer1(out)\r\n","        out = self.layer2(out)\r\n","        out = self.layer3(out)\r\n","        out = self.layer4(out)\r\n","        out = F.avg_pool2d(out, 4)\r\n","        out = out.view(out.size(0), -1)\r\n","        out = self.linear(out)\r\n","        return out\r\n","\r\n","\r\n","# ResNet18 함수 정의\r\n","def ResNet18():\r\n","    return ResNet(BasicBlock, [2, 2, 2, 2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1GkQw0buFcfB"},"source":["import torchvision\r\n","import torchvision.transforms as transforms\r\n","\r\n","transform_train = transforms.Compose([\r\n","                                      transforms.RandomCrop(32, padding=4),\r\n","                                      transforms.RandomHorizontalFlip(),\r\n","                                      transforms.ToTensor(),\r\n","])\r\n","\r\n","transform_test = transforms.Compose([\r\n","                                    transforms.ToTensor(),\r\n","                                    ])\r\n","\r\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\r\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\r\n","\r\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\r\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNLs278ZGgIk"},"source":["device = 'cuda'\r\n","\r\n","net = ResNet18()\r\n","net = net.to(device)\r\n","net = torch.nn.DataParallel(net)\r\n","cudnn.benchmark = True\r\n","\r\n","learning_rate = 0.1\r\n","file_name = 'resnet18_cifar10.pt'\r\n","\r\n","criterion = nn.CrossEntropyLoss()\r\n","optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\r\n","\r\n","\r\n","def train(epoch):\r\n","    print('\\n[ Train epoch: %d ]' % epoch)\r\n","    net.train()\r\n","    train_loss = 0\r\n","    correct = 0\r\n","    total = 0\r\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\r\n","        inputs, targets = inputs.to(device), targets.to(device)\r\n","        optimizer.zero_grad()\r\n","\r\n","        benign_outputs = net(inputs)\r\n","        loss = criterion(benign_outputs, targets)\r\n","        loss.backward()\r\n","\r\n","        optimizer.step()\r\n","        train_loss += loss.item()\r\n","        _, predicted = benign_outputs.max(1)\r\n","\r\n","        total += targets.size(0)\r\n","        correct += predicted.eq(targets).sum().item()\r\n","        \r\n","        if batch_idx % 100 == 0:\r\n","            print('\\nCurrent batch:', str(batch_idx))\r\n","            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\r\n","            print('Current benign train loss:', loss.item())\r\n","\r\n","    print('\\nTotal benign train accuarcy:', 100. * correct / total)\r\n","    print('Total benign train loss:', train_loss)\r\n","\r\n","\r\n","def test(epoch):\r\n","    print('\\n[ Test epoch: %d ]' % epoch)\r\n","    net.eval()\r\n","    loss = 0\r\n","    correct = 0\r\n","    total = 0\r\n","\r\n","    for batch_idx, (inputs, targets) in enumerate(test_loader):\r\n","        inputs, targets = inputs.to(device), targets.to(device)\r\n","        total += targets.size(0)\r\n","\r\n","        outputs = net(inputs)\r\n","        loss += criterion(outputs, targets).item()\r\n","\r\n","        _, predicted = outputs.max(1)\r\n","        correct += predicted.eq(targets).sum().item()\r\n","\r\n","    print('\\nTest accuarcy:', 100. * correct / total)\r\n","    print('Test average loss:', loss / total)\r\n","\r\n","    state = {\r\n","        'net': net.state_dict()\r\n","    }\r\n","    if not os.path.isdir('checkpoint'):\r\n","        os.mkdir('checkpoint')\r\n","    torch.save(state, './checkpoint/' + file_name)\r\n","    print('Model Saved!')\r\n","\r\n","\r\n","def adjust_learning_rate(optimizer, epoch):\r\n","    lr = learning_rate\r\n","    if epoch >= 100:\r\n","        lr /= 10\r\n","    if epoch >= 150:\r\n","        lr /= 10\r\n","    for param_group in optimizer.param_groups:\r\n","        param_group['lr'] = lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clKLGZHxRZMK"},"source":["# for epoch in range(0, 200):\r\n","for epoch in range(0, 20):\r\n","    adjust_learning_rate(optimizer, epoch)\r\n","    train(epoch)\r\n","    test(epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VN532iZSR3Dc"},"source":[""],"execution_count":null,"outputs":[]}]}